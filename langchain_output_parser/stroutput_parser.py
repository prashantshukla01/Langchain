from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 1Ô∏è‚É£ Hugging Face endpoint (CHAT / conversational model)
llm_endpoint = HuggingFaceEndpoint(
    repo_id="HuggingFaceH4/zephyr-7b-beta",
    task="conversational",        # üî• REQUIRED
    max_new_tokens=256,
    temperature=0.7
)

# 2Ô∏è‚É£ Wrap with ChatHuggingFace (MANDATORY for chat models)
chat_model = ChatHuggingFace(llm=llm_endpoint)

# 3Ô∏è‚É£ Prompt
prompt = PromptTemplate(
    template="Explain {topic} in simple words.",
    input_variables=["topic"]
)

# 4Ô∏è‚É£ Output parser (string)
parser = StrOutputParser()

# 5Ô∏è‚É£ Chain (Prompt ‚Üí Chat Model ‚Üí String)
chain = prompt | chat_model | parser

# 6Ô∏è‚É£ Invoke
result = chain.invoke({"topic": "Black Hole"})
print(result)
